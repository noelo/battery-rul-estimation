{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jw9FMur02UtZ"
   },
   "source": [
    "# Autoencoder UNIBO Powertools Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKxZ90kO2Uta"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import math\n",
    "import ntpath\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from importlib import reload\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "IS_COLAB = False\n",
    "IS_TRAINING = False\n",
    "RESULT_NAME = \"\"\n",
    "IS_OFFLINE = True\n",
    "\n",
    "if IS_OFFLINE:\n",
    "    import plotly.offline as pyo\n",
    "    pyo.init_notebook_mode()\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    data_path = \"/content/drive/My Drive/battery-state-estimation/battery-state-estimation/\"\n",
    "else:\n",
    "    data_path = \"../../\"\n",
    "\n",
    "sys.path.append(data_path)\n",
    "from data_processing.unibo_powertools_data import UniboPowertoolsData, CycleCols\n",
    "from data_processing.model_data_handler import ModelDataHandler\n",
    "from data_processing.prepare_rul_data import RulHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfVCRISs2Utc"
   },
   "source": [
    "### Config logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2IvySBk2Utd"
   },
   "outputs": [],
   "source": [
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s [%(levelname)s]: %(message)s', level=logging.DEBUG, datefmt='%Y/%m/%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsbkwTX22Utf"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrHYRy-a2Utg"
   },
   "outputs": [],
   "source": [
    "dataset = UniboPowertoolsData(\n",
    "    test_types=[],\n",
    "    chunk_size=1000000,\n",
    "    lines=[37, 40],\n",
    "    charge_line=37,\n",
    "    discharge_line=40,\n",
    "    base_path=data_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSFp-2Rl2Utj"
   },
   "outputs": [],
   "source": [
    "train_names = [\n",
    "    '000-DM-3.0-4019-S',#minimum capacity 1.48\n",
    "    '001-DM-3.0-4019-S',#minimum capacity 1.81\n",
    "    '002-DM-3.0-4019-S',#minimum capacity 2.06\n",
    "\n",
    "    '009-DM-3.0-4019-H',#minimum capacity 1.41\n",
    "    '010-DM-3.0-4019-H',#minimum capacity 1.44\n",
    "\n",
    "    '014-DM-3.0-4019-P',#minimum capacity 1.7\n",
    "    '015-DM-3.0-4019-P',#minimum capacity 1.76\n",
    "    '016-DM-3.0-4019-P',#minimum capacity 1.56\n",
    "    '017-DM-3.0-4019-P',#minimum capacity 1.29\n",
    "    #'047-DM-3.0-4019-P',#new 1.98\n",
    "    #'049-DM-3.0-4019-P',#new 2.19\n",
    "\n",
    "\n",
    "\n",
    "    '007-EE-2.85-0820-S',#2.5\n",
    "    '008-EE-2.85-0820-S',#2.49\n",
    "    '042-EE-2.85-0820-S',#2.51\n",
    "\n",
    "    '043-EE-2.85-0820-H',#2.31\n",
    "\n",
    "\n",
    "    '040-DM-4.00-2320-S',#minimum capacity 3.75, cycles 188\n",
    "\n",
    "\n",
    "    '018-DP-2.00-1320-S',#minimum capacity 1.82\n",
    "    #'019-DP-2.00-1320-S',#minimum capacity 1.61\n",
    "    '036-DP-2.00-1720-S',#minimum capacity 1.91\n",
    "    '037-DP-2.00-1720-S',#minimum capacity 1.84\n",
    "    '038-DP-2.00-2420-S',#minimum capacity 1.854 (to 0)\n",
    "    '050-DP-2.00-4020-S',#new 1.81\n",
    "    '051-DP-2.00-4020-S',#new 1.866    \n",
    "    \n",
    "]\n",
    "\n",
    "test_names = [\n",
    "    '003-DM-3.0-4019-S',#minimum capacity 1.84\n",
    "\n",
    "    '011-DM-3.0-4019-H',#minimum capacity 1.36\n",
    "\n",
    "    '013-DM-3.0-4019-P',#minimum capacity 1.6\n",
    "\n",
    "\n",
    "\n",
    "    '006-EE-2.85-0820-S',# 2.621\n",
    "    \n",
    "    '044-EE-2.85-0820-H',# 2.43\n",
    "\n",
    "\n",
    "\n",
    "    '039-DP-2.00-2420-S',#minimum capacity 1.93\n",
    "\n",
    "\n",
    "\n",
    "    '041-DM-4.00-2320-S',#minimum capacity 3.76, cycles 190\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-yTrXQ12Utm"
   },
   "outputs": [],
   "source": [
    "dataset.prepare_data(train_names, test_names)\n",
    "dataset_handler = ModelDataHandler(dataset, [\n",
    "    CycleCols.VOLTAGE,\n",
    "    CycleCols.CURRENT,\n",
    "    CycleCols.TEMPERATURE\n",
    "])\n",
    "\n",
    "rul_handler = RulHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAAxueIqkZM9"
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbntMzBZkZM9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "(train_x, train_y_soh, test_x, test_y_soh,\n",
    "  train_battery_range, test_battery_range,\n",
    "  time_train, time_test, current_train, current_test) = dataset_handler.get_discharge_whole_cycle_future(\n",
    "    train_names, \n",
    "    test_names, \n",
    "    # match decoder output\n",
    "    min_cycle_length=300)\n",
    "\n",
    "# train_x = train_x[:,:284,:]\n",
    "# test_x = test_x[:,:284,:]\n",
    "# print(\"cut train shape {}\".format(train_x.shape))\n",
    "# print(\"cut test shape {}\".format(test_x.shape))\n",
    "\n",
    "\n",
    "x_norm = rul_handler.Normalization()\n",
    "train_x, test_x = x_norm.fit_and_normalize(train_x, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iYU-n0K2Utq"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSx96n4w2Uts"
   },
   "outputs": [],
   "source": [
    "if IS_TRAINING:\n",
    "    EXPERIMENT = \"autoencoder_gl_unibo_powertools\"\n",
    "\n",
    "    experiment_name = time.strftime(\"%Y-%m-%d-%H-%M-%S\") + '_' + EXPERIMENT\n",
    "    print(experiment_name)\n",
    "\n",
    "# Model definition\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "LATENT_DIM = 10\n",
    "\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        encoder_inputs = layers.Input(shape=(train_x.shape[1], train_x.shape[2]))\n",
    "        encoder_conv1 = layers.Conv1D(filters=8, kernel_size=10, strides=2, activation='relu', padding='same')(encoder_inputs)\n",
    "        encoder_pool1 = layers.MaxPooling1D(5, padding='same')(encoder_conv1)\n",
    "        encoder_conv2 = layers.Conv1D(filters=8, kernel_size=4, strides=1, activation='relu', padding='same')(encoder_pool1)\n",
    "        encoder_pool2 = layers.MaxPooling1D(3, padding='same')(encoder_conv2)\n",
    "        encoder_flat1 = layers.Flatten()(encoder_pool1)\n",
    "        encoder_flat2 = layers.Flatten()(encoder_pool2)\n",
    "        encoder_concat = layers.concatenate([encoder_flat1, encoder_flat2])\n",
    "        encoder_outputs = layers.Dense(self.latent_dim, activation='relu')(encoder_concat)\n",
    "        self.encoder = Model(inputs=encoder_inputs, outputs=encoder_outputs)\n",
    "\n",
    "        decoder_inputs = layers.Input(shape=(self.latent_dim,))\n",
    "        decoder_dense1 = layers.Dense(10*8, activation='relu')(decoder_inputs)\n",
    "        decoder_reshape1 = layers.Reshape((10, 8))(decoder_dense1)\n",
    "        decoder_upsample1 = layers.UpSampling1D(3)(decoder_reshape1)\n",
    "        decoder_convT1 = layers.Conv1DTranspose(filters=8, kernel_size=4, strides=1, activation='relu', padding='same')(decoder_upsample1)\n",
    "        decoder_upsample2 = layers.UpSampling1D(5)(decoder_convT1)\n",
    "        decoder_convT2 = layers.Conv1DTranspose(filters=8, kernel_size=10, strides=2, activation='relu', padding='same')(decoder_upsample2)\n",
    "        decoder_outputs = layers.Conv1D(3, kernel_size=3, activation='relu', padding='same')(decoder_convT2)\n",
    "        self.decoder = Model(inputs=decoder_inputs, outputs=decoder_outputs)\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "autoencoder = Autoencoder(LATENT_DIM)\n",
    "autoencoder.compile(optimizer=opt, loss='mse', metrics=['mse', 'mae', 'mape', tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "autoencoder.encoder.summary()\n",
    "autoencoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIEcv6Ey2Utu"
   },
   "outputs": [],
   "source": [
    "if IS_TRAINING:\n",
    "    history = autoencoder.fit(train_x, train_x,\n",
    "                                epochs=500, \n",
    "                                batch_size=32, \n",
    "                                verbose=1,\n",
    "                                validation_split=0.1\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNHlqcvP2Utx"
   },
   "outputs": [],
   "source": [
    "if IS_TRAINING:\n",
    "    autoencoder.save_weights(data_path + 'results/trained_model/%s/model' % experiment_name)\n",
    "\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_csv_file = data_path + 'results/trained_model/%s/history.csv' % experiment_name\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "    history = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_TRAINING:\n",
    "    history = pd.read_csv(data_path + 'results/trained_model/%s/history.csv' % RESULT_NAME)\n",
    "    autoencoder.load_weights(data_path + 'results/trained_model/%s/model' % RESULT_NAME)\n",
    "    autoencoder.encoder.summary()\n",
    "    autoencoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_TRAINING:\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LH5RANQIEQVx"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggNKW-VqENFN"
   },
   "outputs": [],
   "source": [
    "results = autoencoder.evaluate(test_x, test_x, return_dict = True)\n",
    "print(results)\n",
    "max_rmse = 0\n",
    "for index in range(test_x.shape[0]):\n",
    "    result = autoencoder.evaluate(np.array([test_x[index, :, :]]), np.array([test_x[index, :, :]]), return_dict = True, verbose=0)\n",
    "    max_rmse = max(max_rmse, result['rmse'])\n",
    "print(\"Max rmse: {}\".format(max_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiqyD8Bn2Utz"
   },
   "source": [
    "# Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jH9RrBRN2Utz"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=history['loss'],\n",
    "                    mode='lines', name='train'))\n",
    "if 'val_loss' in history:\n",
    "    fig.add_trace(go.Scatter(y=history['val_loss'],\n",
    "                    mode='lines', name='validation'))\n",
    "fig.update_layout(title='Loss trend',\n",
    "                  xaxis_title='epoch',\n",
    "                  yaxis_title='loss',\n",
    "                  width=1400,\n",
    "                  height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = autoencoder.predict(train_x)\n",
    "labels = ['Voltage', 'Current', 'Temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_x.shape[2]):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=train_predictions[0,:,i],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=train_x[0,:,i],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on training - battery new',\n",
    "                    xaxis_title='Step',\n",
    "                    yaxis_title=labels[i],\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_x.shape[2]):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=train_predictions[int(train_battery_range[0]/2),:,i],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=train_x[int(train_battery_range[0]/2),:,i],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on training - middle life',\n",
    "                    xaxis_title='Step',\n",
    "                    yaxis_title=labels[i],\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_x.shape[2]):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=train_predictions[train_battery_range[0]-1,:,i],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=train_x[train_battery_range[0]-1,:,i],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on training - end of life',\n",
    "                    xaxis_title='Step',\n",
    "                    yaxis_title=labels[i],\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = autoencoder.predict(test_x)\n",
    "labels = ['Voltage', 'Current', 'Temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_x.shape[2]):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=test_predictions[0,:,i],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=test_x[0,:,i],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on testing - battery new',\n",
    "                    xaxis_title='Step',\n",
    "                    yaxis_title=labels[i],\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_x.shape[2]):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=test_predictions[int(test_battery_range[0]/2),:,i],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=test_x[0,:,i],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on testing - middle life',\n",
    "                    xaxis_title='Step',\n",
    "                    yaxis_title=labels[i],\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_x.shape[2]):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=test_predictions[test_battery_range[0]-1,:,i],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=test_x[0,:,i],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on testing - end of life',\n",
    "                    xaxis_title='Step',\n",
    "                    yaxis_title=labels[i],\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lstm_soh_prediction_only_future.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlpipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "4d986fe50fa739c38d5d10f0a6cd2cbd026b3a04e17af08ef320d31a31a2c11a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
